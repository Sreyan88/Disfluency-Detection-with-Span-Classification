{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em3xGn9eXvDf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XF8zscUyYGvJ",
    "outputId": "796825e9-d929-4897-c21a-063ab651f2e0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('switchboard.tsv', sep='\\t')\n",
    "print(df) \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxxEl7qSZl3z"
   },
   "outputs": [],
   "source": [
    "df.drop(['speaker', 'turn', 'sent_num', 'sentence', 'comb_sentence', 'names', 'ms_names', 'comb_ann', 'first_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKJmltGIhAi_"
   },
   "outputs": [],
   "source": [
    "rows1 = df['file'].str.contains(\"sw[23]\")\n",
    "rows2= df['file'].str.contains(\"sw4[5-9]\")\n",
    "rows3 = df['file'].str.contains(\"sw4[0-1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcaFPfusYrHx",
    "outputId": "1231a15c-61e9-4133-88f3-7746b9fcb2f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def getList(string):\n",
    "    l = ast.literal_eval(string)\n",
    "    return l\n",
    "\n",
    "df['words'] = df['ms_sentence'].apply(getList)\n",
    "df['tags'] = df['ms_disfl'].apply(getList)\n",
    "print(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfZUiM7kmJPJ",
    "outputId": "b677f443-07f4-4d57-a5f9-9db907be8d96"
   },
   "outputs": [],
   "source": [
    "df.drop(['ms_sentence', 'ms_disfl'], axis=1, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mrUYlzWmVtt",
    "outputId": "de3dd9cd-1ae8-433c-e394-07edbcbcf649"
   },
   "outputs": [],
   "source": [
    "def changeTags(tags):\n",
    "    for i in range(len(tags)):\n",
    "        if tags[i] == 'C' or tags[i] == 'O':\n",
    "            tags[i] = 'O'\n",
    "        else:\n",
    "            tags[i] = 'I'\n",
    "    return tags\n",
    "\n",
    "df['tags'] = df['tags'].apply(changeTags)\n",
    "print(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in df.tags:\n",
    "    if all(ele=='O' for ele in i):\n",
    "        continue\n",
    "    else:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9hKP6zisyty",
    "outputId": "74095235-3a1b-45b3-e40e-bf9aeefd68a0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_partial_and_fp(row):\n",
    "    words = row['words']\n",
    "    tags = row['tags']\n",
    "    n_tags = []\n",
    "    n_words = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(words):\n",
    "        removed = re.sub(r'[/-]+', \"\", words[i])\n",
    "        if words[i] == 'uh' or words[i] == 'um':\n",
    "            i += 1\n",
    "            j += 1\n",
    "        # elif i<len(words)-1 and words[i] == 'i' and words[i+1] == 'mean':\n",
    "        #     n_words.append(words[i]+ \" \" +words[i+1])\n",
    "        #     n_tags.append(tags[j+1])\n",
    "        #     i += 2\n",
    "        #     j += 2\n",
    "        # elif i<len(words)-1 and words[i] == 'you' and words[i+1] == 'know':\n",
    "        #     n_words.append(words[i]+\" \"+words[i+1])\n",
    "        #     n_tags.append(tags[j+1])\n",
    "        #     i += 2\n",
    "        #     j += 2\n",
    "        elif len(removed) == 0:\n",
    "            i += 1\n",
    "        elif words[i][-1] == '-':\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            n_words.append(words[i])\n",
    "            n_tags.append(tags[j])\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "    row['words'] = n_words\n",
    "    row['tags'] = n_tags\n",
    "    return row\n",
    "\n",
    "df = df.apply(remove_partial_and_fp, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWlWPhdo1-GQ"
   },
   "outputs": [],
   "source": [
    "mask = df['words'].notnull()\n",
    "df.loc[mask,'words'] = [' '.join(map(str, x)) for x in df.loc[mask,'words']]\n",
    "mask = df['tags'].notnull()\n",
    "df.loc[mask,'tags'] = [' '.join(map(str, x)) for x in df.loc[mask,'tags']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffXBT4hQ5jpI",
    "outputId": "2a7570d4-e6e0-485c-abcb-aad5bae1138b"
   },
   "outputs": [],
   "source": [
    "z=df\n",
    "def checkLength(x):\n",
    "    return len(x[0].split(' '))==len(x[1].split(' '))\n",
    "\n",
    "\n",
    "z['length'] = z.apply(checkLength,axis=1)\n",
    "z.drop(z[ z['length'] == False].index, inplace=True)\n",
    "z.reset_index(drop=True)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZ_-igwyBywb"
   },
   "outputs": [],
   "source": [
    "cols = ['words','tags']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUzbHFJu5lB_",
    "outputId": "0fc9bae6-0fe5-4588-af4f-f5f5fb59b1e3"
   },
   "outputs": [],
   "source": [
    "test = df[rows3].reset_index(drop=True)\n",
    "dev = (df[rows2]).reset_index(drop=True)\n",
    "train = (df[rows1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suNTUp5z0ZF0"
   },
   "outputs": [],
   "source": [
    "# unlabel = train.drop(['tags','none1','none2'], axis=1).reset_index(drop=True)\n",
    "# unlabel['none1']='None'\n",
    "# unlabel['none2']='None'\n",
    "# unlabel['none3']='None'\n",
    "\n",
    "# unlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XhJyeB0zaRc"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train.txt', sep='\\t', header=False, index=False)\n",
    "dev.to_csv('dev.txt', sep='\\t', header=False, index=False) \n",
    "test.to_csv('test.txt', sep='\\t', header=False, index=False)\n",
    "# unlabel.to_csv('unlabel.tsv',sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUPvLeit1aYD"
   },
   "outputs": [],
   "source": [
    "# !mv train.txt /content/drive/MyDrive/btp\n",
    "# !mv test.txt /content/drive/MyDrive/btp\n",
    "# !mv dev.txt /content/drive/MyDrive/btp\n",
    "# !mv unlabel.tsv /content/drive/MyDrive/btp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following code to convert IO to BIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test.txt','r',encoding='utf-8')\n",
    "file = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('Data_IO_to_BIO/test.txt','a',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i,line in tqdm(enumerate(file)):\n",
    "    tmp = line.split('\\t')\n",
    "    sent = tmp[0].split()\n",
    "#     print(sent)\n",
    "    tags = tmp[1].strip().split()\n",
    "    for i in range(len(sent)):\n",
    "        if tags[i] == \"I\":\n",
    "            if i == 0:\n",
    "                tags[i] = \"B-Target\"\n",
    "            elif tags[i-1] == \"O\":\n",
    "                tags[i] = \"B-Target\" \n",
    "            else:\n",
    "                tags[i] =  tags[i]+\"-Target\"\n",
    "        file2.write(sent[i]+\"\\t\"+tags[i]+\"\\n\")\n",
    "    file2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To add the heads in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supar import Parser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser.load('biaffine-dep-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Data_IO_to_BIO/test.txt','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "tokens = []\n",
    "tags = []\n",
    "for line in tqdm(file):\n",
    "    if len(line.strip()) == 0:\n",
    "        if len(tokens) != 0:\n",
    "            texts.append(tokens)\n",
    "            labels.append(tags)\n",
    "            tokens = []\n",
    "            tags = []\n",
    "    else:\n",
    "        if len(line.strip()) != 0:\n",
    "            sp = line.split()\n",
    "            tokens.append(sp[0])\n",
    "            tags.append(sp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "for i in texts:\n",
    "    sents.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parser.predict(sents, lang='en', prob=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../Data_graph_temp/train_without_labels.txt\",'a',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    file.write(str(dataset[i]))\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../Data_graph_temp/train_without_labels.txt\",'r',encoding='utf-8')\n",
    "file = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"../Data_graph_temp/train_labels_temp.txt\",'a',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for i in labels:\n",
    "    for j in i:\n",
    "        tags.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = -1\n",
    "k = 0\n",
    "for i,line in enumerate(file):\n",
    "    if len(line.strip()) == 0:\n",
    "        file1.write(\"\\n\")\n",
    "        k = 0\n",
    "    elif line.startswith(\"1\\t\"):\n",
    "        if k >= len(labels[j]):\n",
    "            continue\n",
    "        j += 1\n",
    "        file1.write(line.strip()+\"\\t\"+labels[j][k]+\"\\n\")\n",
    "        k += 1\n",
    "    else:\n",
    "        if k >= len(labels[j]):\n",
    "            continue\n",
    "        file1.write(line.strip()+\"\\t\"+labels[j][k]+\"\\n\")\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../Data_graph_temp/train_labels_temp.txt\",'r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "words = []\n",
    "lols1 = []\n",
    "poss1 = []\n",
    "poss2 = []\n",
    "lols2 = []\n",
    "headss = []\n",
    "relss = []\n",
    "lols3 = []\n",
    "lols4 = []\n",
    "labless = []\n",
    "\n",
    "num = []\n",
    "word = []\n",
    "lol1 = []\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "lol2 = []\n",
    "heads = []\n",
    "rels = []\n",
    "lol3 = []\n",
    "lol4 = []\n",
    "lables = []\n",
    "for line in tqdm(file):\n",
    "#     print(line)\n",
    "    if line.strip() == \"\":\n",
    "        nums.append(num)\n",
    "        words.append(word)\n",
    "        lols1.append(lol1)\n",
    "        poss1.append(pos1)\n",
    "        poss2.append(pos2)\n",
    "        lols2.append(lol2)\n",
    "        headss.append(heads)\n",
    "        relss.append(rels)\n",
    "        lols3.append(lol3)\n",
    "        lols4.append(lol4)\n",
    "        labless.append(lables)\n",
    "        num = []\n",
    "        word = []\n",
    "        lol1 = []\n",
    "        pos1 = []\n",
    "        pos2 = []\n",
    "        lol2 = []\n",
    "        heads = []\n",
    "        rels = []\n",
    "        lol3 = []\n",
    "        lol4 = []\n",
    "        lables = []\n",
    "    else:\n",
    "        temp = line.strip().split(\"\\t\")\n",
    "        num.append(temp[0])\n",
    "        word.append(temp[1])\n",
    "        lol1.append(temp[2])\n",
    "        pos1.append(temp[3])\n",
    "        pos2.append(temp[4])\n",
    "        lol2.append(temp[5])\n",
    "        heads.append(temp[6])\n",
    "        rels.append(temp[7])\n",
    "        lol3.append(temp[8])\n",
    "        lol4.append(temp[9])\n",
    "        lables.append(temp[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"../Data_BIO/test.txt\", \"a\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nums)):\n",
    "    for j in range(len(nums[i])):\n",
    "        if int(headss[i][j]) > len(nums[i]):\n",
    "            headss[i][j] = int(headss[i][j]) - 3\n",
    "        if int(headss[i][j]) == len(nums[i]):\n",
    "            headss[i][j] = int(headss[i][j]) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nums)):\n",
    "    for j in range(len(nums[i])):\n",
    "        file2.write(nums[i][j]+\"\\t\"+words[i][j]+\"\\t\"+lols1[i][j]+\"\\t\"+poss1[i][j]+\"\\t\"+poss2[i][j]+\"\\t\"+lols2[i][j]+\"\\t\"+str(headss[i][j])+\"\\t\"+relss[i][j]+\"\\t\"+lols3[i][j]+\"\\t\"+lols4[i][j]+\"\\t\"+labless[i][j]+\"\\n\")\n",
    "    file2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data obtained now in the \"Data_BIO\" folder is now ready to be run through the dataprocess/bio2spannerformat.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prepare switchboard.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
